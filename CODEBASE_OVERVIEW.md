# DeepSeeker Codebase Comprehensive Overview

## Executive Summary

**DeepSeeker** is a local-first neural search engine for Markdown and PDF documentation. It's built with Rust (backend) and React/TypeScript (frontend), using a hybrid search approach combining BM25 keyword search (FTS5) with semantic vector search (sqlite-vec + ONNX embeddings).

**Current Status**: Phase 1 Complete - Core engine fully implemented with 30+ unit tests passing. Architecture is production-ready with SQLite-based hybrid search fully optimized for 10-100x performance improvement.

---

## 1. Project Structure

```
deepseeker/
â”œâ”€â”€ src-tauri/                 # Rust backend (Tauri v2)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.rs           # Entry point, app initialization
â”‚   â”‚   â”œâ”€â”€ lib.rs            # Library root, module declarations
â”‚   â”‚   â”œâ”€â”€ commands.rs        # Tauri IPC commands (index, search, collection mgmt)
â”‚   â”‚   â”œâ”€â”€ db.rs             # Database initialization, schema, queries
â”‚   â”‚   â”œâ”€â”€ chunker.rs        # Markdown AST-based chunking algorithm
â”‚   â”‚   â”œâ”€â”€ embeddings.rs     # BAAI/bge-m3 ONNX model wrapper
â”‚   â”‚   â”œâ”€â”€ search.rs         # Hybrid search (BM25 + Vector)
â”‚   â”‚   â”œâ”€â”€ models.rs         # Data structures (Collection, Document, Chunk, SearchResult)
â”‚   â”‚   â”œâ”€â”€ pdf_parser.rs     # PDF text extraction (pdf-extract)
â”‚   â”‚   â”œâ”€â”€ watcher.rs        # File system watching (notify crate)
â”‚   â”‚   â””â”€â”€ http_server.rs    # Browser extension HTTP server
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â””â”€â”€ fixtures/
â”‚   â”‚       â””â”€â”€ sample_readme.md  # Test fixture (200+ lines)
â”‚   â”œâ”€â”€ Cargo.toml            # Rust dependencies
â”‚   â””â”€â”€ build.rs              # Build script (Tauri)
â”‚
â”œâ”€â”€ src/                       # React/TypeScript frontend
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ SearchInterface.tsx
â”‚   â”‚   â”œâ”€â”€ CollectionManager.tsx
â”‚   â”‚   â”œâ”€â”€ CreateCollectionDialog.tsx
â”‚   â”‚   â”œâ”€â”€ ModelManager.tsx
â”‚   â”‚   â”œâ”€â”€ ValidationTest.tsx    # Phase 1 validation UI
â”‚   â”‚   â”œâ”€â”€ Settings.tsx
â”‚   â”‚   â””â”€â”€ SearchFilters.tsx
â”‚   â”œâ”€â”€ App.tsx                # Main app component
â”‚   â””â”€â”€ styles.css
â”‚
â”œâ”€â”€ browser-extension/          # Browser extension (future)
â”‚   â”œâ”€â”€ manifest.json
â”‚   â”œâ”€â”€ background.js
â”‚   â””â”€â”€ content.js
â”‚
â”œâ”€â”€ test-data/
â”‚   â””â”€â”€ validation_test.md      # 210 lines of test data with deep nesting
â”‚
â”œâ”€â”€ README.md                   # Main documentation
â”œâ”€â”€ PHASE1_SUMMARY.md           # Detailed phase 1 completion report
â”œâ”€â”€ performance_test_plan.md    # Performance benchmarking strategy
â””â”€â”€ package.json               # Node.js dependencies

```

---

## 2. Current Implementations

### 2.1 Database & Schema (db.rs - 240+ lines)

**Technology**: SQLite with FTS5 + sqlite-vec

**Tables**:
- `collections` - Collection metadata (name, folder_path, file_count, last_sync)
- `documents` - Document references (collection_id, path, hash, last_modified, status)
- `chunks` - Indexed chunks (doc_id, content, metadata JSON, start_line, end_line, embedding BLOB)
- `chunks_fts` - FTS5 virtual table for full-text search
- `chunks_vec` - sqlite-vec virtual table for KNN vector search (float[1024])

**Key Features**:
- WAL mode enabled for concurrency
- Automatic triggers to keep FTS5 and vector indices in sync
- Cascade delete for referential integrity
- Ghost data cleanup (removes documents pointing to deleted files)
- Per-file hash-based deduplication

**Status**: âœ… Complete with 6 unit tests

### 2.2 Markdown Parsing & Chunking (chunker.rs - 387+ lines)

**Algorithm**: AST-based structure-aware chunking using pulldown-cmark

**Key Principles**:
1. **Never split code blocks** - Entire code blocks preserved regardless of size
2. **Header context preservation** - Maintains hierarchy (H1 > H2 > H3 > H4)
3. **Semantic boundary protection** - Chunks respect logical document structure

**Chunking Logic**:
- Tracks header stack as Markdown is parsed
- Code blocks (fenced and indented) stored as atomic units
- Text content split at MAX_CHUNK_SIZE (1000 chars) only for paragraphs
- Each chunk stores:
  - Content (string)
  - Headers (Vec<String> - full hierarchy path)
  - Type ("code" or "text")
  - Language (for code blocks, e.g., "python", "rust")
  - Start/end line numbers

**Test Coverage**: 10 complex test scenarios:
- Deep nesting (H1>H2>H3>H4>H5 with code)
- Multiple code blocks in same header
- Special character handling
- Long text chunking
- Realistic README parsing

**Status**: âœ… Complete with proven reliability

### 2.3 Vector Embeddings (embeddings.rs - 237 lines)

**Model**: BAAI/bge-m3 (Multilingual BGE)
- Output dimension: 1024
- Type: Dense embeddings (SOTA for semantic search)
- Inference: ONNX Runtime v2.0

**Implementation**:
- Batch embedding support for efficiency
- Tokenization via HuggingFace tokenizers
- Sequence padding to 512 tokens
- Cosine similarity computation
- Vector normalization for unit vectors

**Model Setup**:
- Expected location: `~/.deepseeker/models/bge-m3/`
  - `model.onnx` (ONNX format model)
  - `tokenizer.json` (HuggingFace tokenizer)
- Download from HuggingFace: https://huggingface.co/BAAI/bge-m3

**Fallback Mechanism**: When model unavailable, search falls back to BM25 only

**Status**: âœ… Complete with 3 unit tests

### 2.4 Hybrid Search (search.rs - 206+ lines)

**Architecture**: Two-stage retrieval with weighted ranking

**Algorithm**:
```
Stage 1: BM25 Keyword Search (via FTS5)
  - Get candidate chunks (limit Ã— 3)
  - Normalize FTS5 rank to [0,1]

Stage 2: Vector KNN Search (via sqlite-vec)
  - Embed query using BAAI/bge-m3
  - Find k-nearest neighbors (cosine distance)
  - Convert distance to similarity score

Stage 3: Hybrid Ranking
  - For each chunk: hybrid_score = 0.7 Ã— vec_score + 0.3 Ã— bm25_score
  - Sort by hybrid score (descending)
  - Return top-k results
```

**Weights**:
- Vector: 0.7 (captures semantic similarity)
- BM25: 0.3 (captures keyword specificity)
- Rationale: Semantic search more important but keywords prevent false positives

**Features**:
- Collection-aware filtering
- Graceful fallback to BM25 if embeddings unavailable
- Score normalization (prevents score range issues)
- Efficient sqlite-vec KNN queries (10-100x faster than full table scans)

**Test Coverage**: 6 test scenarios:
- Empty database search
- BM25 score normalization
- F32 serialization/deserialization
- Weight verification
- Hybrid search fallback mechanism

**Status**: âœ… Complete and optimized

### 2.5 File Indexing (commands.rs - 400+ lines)

**Features**:
- Recursive directory traversal (Markdown + PDF files)
- Incremental indexing (skip unchanged files via SHA256 hash)
- PDF text extraction (pdf-extract crate)
- PDF scanned detection (heuristic: <50 chars/page)
- Automatic document status tracking (normal/scanned_pdf/error)
- Progress tracking (for long operations)

**Indexing Flow**:
1. Walk directory for .md, .markdown, .pdf files
2. Compute SHA256 hash of content
3. Skip if same hash exists (no changes)
4. Otherwise: chunk content + store metadata
5. Generate embeddings for chunks
6. Insert into SQLite with FTS5/vector triggers

**Collections**:
- Create named collections pointing to directories
- Full reindex capability
- Delete with cascade cleanup

**Status**: âœ… Working with PDF support

### 2.6 File Watching (watcher.rs - 66 lines)

**Technology**: notify crate (RecommendedWatcher - inotify on Linux)

**Features**:
- Real-time file change detection
- 2-second debounce interval
- Event emission to frontend (file-changed, file-removed)
- Collection-aware watching

**Current State**: âš ï¸ Basic infrastructure in place, but incremental indexing not fully integrated yet

**TODO**: 
- Connect file events to automatic chunk updates
- Handle incremental updates without full reindex
- Deduplicate chunk content on update

**Status**: ðŸŸ¡ Partially implemented

---

## 3. Database Schema Details

### Collections Table
```sql
CREATE TABLE collections (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name TEXT NOT NULL UNIQUE,
  folder_path TEXT,
  file_count INTEGER DEFAULT 0,
  last_sync INTEGER,
  created_at INTEGER NOT NULL,
  updated_at INTEGER NOT NULL
)
```

### Documents Table
```sql
CREATE TABLE documents (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  collection_id INTEGER NOT NULL,
  path TEXT NOT NULL,
  hash TEXT NOT NULL,          -- SHA256 for deduplication
  last_modified INTEGER NOT NULL,
  created_at INTEGER NOT NULL,
  status TEXT DEFAULT 'normal', -- 'normal'|'scanned_pdf'|'error'
  FOREIGN KEY (collection_id) REFERENCES collections(id) ON DELETE CASCADE,
  UNIQUE(collection_id, path)
)
```

### Chunks Table
```sql
CREATE TABLE chunks (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  doc_id INTEGER NOT NULL,
  content TEXT NOT NULL,
  metadata TEXT,                -- JSON: {headers: [...], chunk_type, language}
  start_line INTEGER NOT NULL,
  end_line INTEGER NOT NULL,
  embedding BLOB,               -- f32 vector as LE bytes
  created_at INTEGER NOT NULL,
  FOREIGN KEY (doc_id) REFERENCES documents(id) ON DELETE CASCADE
)
```

### FTS5 Virtual Table
```sql
CREATE VIRTUAL TABLE chunks_fts USING fts5(
  content,
  metadata,
  content_rowid UNINDEXED,
  tokenize = 'porter unicode61'
)
```

**Triggers**: Auto-sync INSERT/UPDATE/DELETE from chunks to chunks_fts

### sqlite-vec Virtual Table
```sql
CREATE VIRTUAL TABLE chunks_vec USING vec0(
  chunk_id INTEGER PRIMARY KEY,
  embedding float[1024]
)
```

**Triggers**: Auto-sync when embedding is added/updated/deleted

---

## 4. Key Entry Points & Commands

### Tauri Commands (RPC Interface)

| Command | Module | Purpose |
|---------|--------|---------|
| `create_collection` | commands.rs | Create new indexed collection |
| `list_collections` | commands.rs | Get all collections |
| `delete_collection` | commands.rs | Delete collection + cascade |
| `index_directory` | commands.rs | Index all MD/PDF in directory |
| `full_reindex` | commands.rs | Clear and re-index collection |
| `search` | commands.rs | Execute hybrid search query |
| `cleanup_ghost_data` | commands.rs | Remove references to deleted files |
| `detect_ghost_files` | commands.rs | Find broken document references |
| `check_model_status` | commands.rs | Check ONNX model availability |
| `start_watching_collections` | commands.rs | Begin file system watching |
| `open_file_at_line` | commands.rs | OS integration (open file in editor) |

### Main Functions

**db.rs**:
- `init_database()` - Initialize schema + extensions
- `get_connection()` - Get SQLite connection
- `cleanup_ghost_data()` - Remove orphaned documents

**chunker.rs**:
- `MarkdownChunker::new()` - Create parser state
- `MarkdownChunker::chunk()` - Parse markdown
- `chunk_markdown()` - Wrapper for commands

**embeddings.rs**:
- `EmbeddingModel::new()` - Load ONNX model
- `EmbeddingModel::embed()` - Single text embedding
- `EmbeddingModel::embed_batch()` - Batch embedding
- `EmbeddingModel::check_model_exists()` - Status check

**search.rs**:
- `search_hybrid()` - Main entry point (selects BM25 or hybrid)
- `hybrid_search_full()` - BM25 + vector search
- `bm25_search_only()` - Fallback keyword search

**watcher.rs**:
- `init_watcher()` - Setup file watching
- `WatcherState` - Shared watcher state

---

## 5. Implementation Status Matrix

### Core Engine

| Component | Status | Test Coverage | Notes |
|-----------|--------|----------------|-------|
| SQLite Setup | âœ… Complete | 6 tests | WAL mode, extensions loaded |
| FTS5 Indexing | âœ… Complete | 6 tests | BM25 ranking working, triggers synced |
| sqlite-vec Integration | âœ… Complete | 1 test | KNN search 10-100x faster |
| Markdown Parsing | âœ… Complete | 10 tests | AST-based, structure-aware |
| ONNX Embeddings | âœ… Complete | 3 tests | BAAI/bge-m3 model integration |
| Hybrid Search | âœ… Complete | 6 tests | 0.7 vec + 0.3 BM25 weights |
| PDF Support | âœ… Complete | - | Text layer support, scanned detection |
| File Hashing | âœ… Complete | - | SHA256 deduplication |
| Ghost Data Cleanup | âœ… Complete | 3 tests | Automatic + manual |

**Total Unit Tests**: 30+

### Data Pipeline

| Component | Status | Notes |
|-----------|--------|-------|
| Directory Indexing | âœ… Complete | Recursive walk, MD+PDF support |
| Incremental Updates | ðŸŸ¡ Partial | File watching in place, but no smart update logic |
| Batch Embedding | âš ï¸ Not Optimized | Currently single-text embeddings only |
| Collection Management | âœ… Complete | Create/list/delete with cascades |
| Progress Tracking | âœ… Complete | Via IndexProgress events |

### Frontend

| Component | Status | Notes |
|-----------|--------|-------|
| Search Interface | âœ… Complete | Query input + results display |
| Collection Manager | âœ… Complete | CRUD operations |
| Model Manager | âœ… Complete | Status check button |
| ValidationTest UI | âœ… Complete | Phase 1 testing component |
| Settings | âœ… Complete | Settings panel |

---

## 6. Technology Stack

### Backend (Rust)

**Database & Search**:
- rusqlite 0.32 - SQLite driver
- sqlite-vec 0.1 - Vector search extension (KNN with cosine distance)
- pulldown-cmark 0.12 - Markdown parsing (AST)

**ML/Embeddings**:
- ort 2.0.0-rc.10 - ONNX Runtime
- ndarray 0.16 - Numerical arrays
- tokenizers 0.20 - HuggingFace tokenizers

**File Handling**:
- walkdir 2 - Directory traversal
- notify 6.1 - File watching
- pdf-extract 0.7 - PDF text extraction
- sha2 0.10 - Hashing
- hex 0.4 - Hex encoding

**HTTP/Async**:
- tokio 1 - Async runtime
- axum 0.7 - HTTP server
- tauri 2.0 - Desktop framework

**Utilities**:
- serde 1.0 - Serialization
- anyhow 1.0 - Error handling
- chrono 0.4 - Timestamps
- log/env_logger - Logging

### Frontend (TypeScript/React)

- React 18.3
- TypeScript 5.6
- @tauri-apps/api - Tauri IPC
- @tanstack/react-query - Server state
- Tailwind CSS - Styling
- React Syntax Highlighter - Code display

---

## 7. What Has Been Implemented

### Phase 1 (Complete - 25 tests):

1. âœ… **Database Infrastructure**
   - SQLite schema with FTS5 & sqlite-vec
   - Automatic schema creation & updates
   - Extension loading (sqlite-vec)
   - Cascade delete for data integrity

2. âœ… **Structure-Aware Chunking**
   - Markdown AST parsing
   - Header hierarchy tracking
   - Code block preservation
   - Line number tracking

3. âœ… **Vector Embeddings**
   - BAAI/bge-m3 ONNX model loading
   - Tokenization & batch processing
   - Vector normalization

4. âœ… **Hybrid Search**
   - BM25 keyword search via FTS5
   - Vector KNN search via sqlite-vec
   - Weighted score combination
   - Graceful BM25 fallback

5. âœ… **File Indexing**
   - Recursive directory walking
   - Markdown + PDF support
   - SHA256 deduplication
   - Progress tracking

6. âœ… **Ghost Data Management**
   - Automatic cleanup on startup
   - Manual cleanup commands
   - Cascade deletion

### Phase 2+ (In Progress/TODO):

1. ðŸŸ¡ **Incremental Indexing**
   - File watching operational (watcher.rs)
   - TODO: Connect to smart update logic
   - TODO: Avoid full re-indexing on change

2. âš ï¸ **Performance Optimization**
   - Batch embedding (currently single-text)
   - Connection pooling
   - Query caching
   - Vector index optimization

3. ðŸ“‹ **Production Features**
   - Error recovery & retry logic
   - Comprehensive logging
   - Configuration files
   - Database backups

---

## 8. What Needs to Be Built

### Priority 1 (Core): 

1. **Incremental Indexing with Smart Updates**
   - Integrate watcher.rs events with indexing
   - Detect modified chunks via hash
   - Update embeddings only for changed chunks
   - Avoid full re-index on every change

2. **Batch Embedding Optimization**
   - Queue chunks during indexing
   - Process in batches (e.g., 100 chunks at a time)
   - Parallel embedding generation
   - Expected speedup: 5-10x

3. **Better Error Handling**
   - Granular error types
   - Retry logic for transient failures
   - User-facing error messages
   - Logging improvement

### Priority 2 (Enhancement):

4. **Advanced Markdown Features**
   - Better table parsing
   - LaTeX math support
   - Callout/admonition detection
   - Meta-data extraction

5. **PDF Improvements**
   - OCR support for scanned PDFs (requires Tesseract)
   - Table extraction
   - Layout-aware chunking

6. **Performance Benchmarking**
   - Implement criterion.rs benchmarks
   - Profile memory usage
   - Optimize query latency

### Priority 3 (Polish):

7. **Configuration System**
   - Config file support (TOML/YAML)
   - User preferences
   - Model selection

8. **UX Improvements**
   - Real-time progress updates
   - Search suggestions
   - Result highlighting
   - Saved searches

9. **Testing Infrastructure**
   - Integration tests
   - End-to-end testing
   - CI/CD pipeline

---

## 9. Key Algorithms & Data Flow

### Hybrid Search Flow

```
User Query: "async python"
  â†“
[search_hybrid]
  â”œâ”€â†’ Try load ONNX model
  â”‚   â”œâ”€ Success: hybrid_search_full()
  â”‚   â””â”€ Fail: bm25_search_only()
  â†“
[Hybrid Path - Full Algorithm]
  â”œâ”€â†’ Generate query embedding (1024-dim vector)
  â”‚
  â”œâ”€â†’ BM25 Search (FTS5):
  â”‚   SELECT * FROM chunks_fts 
  â”‚   WHERE content MATCH "async python"
  â”‚   LIMIT limit Ã— 3  (get 3x candidates)
  â”‚   â””â”€ Normalize FTS5 rank: 1/(1 + |rank|)
  â”‚
  â”œâ”€â†’ Vector Search (sqlite-vec):
  â”‚   SELECT * FROM chunks_vec
  â”‚   WHERE distance_cosine(embedding, ?) < threshold
  â”‚   LIMIT limit Ã— 3
  â”‚   â””â”€ Convert distance to similarity: 1 - distance
  â”‚
  â”œâ”€â†’ Merge Results:
  â”‚   For each unique chunk_id:
  â”‚     hybrid_score = 0.7 Ã— vec_score + 0.3 Ã— bm25_score
  â”‚
  â”œâ”€â†’ Sort by hybrid_score (descending)
  â”‚
  â””â”€â†’ Return top K results + metadata
      (headers, chunk_type, language, line numbers)
```

### Indexing Flow

```
User: "Index /path/to/docs"
  â†“
[index_directory]
  â”œâ”€â†’ Walk directory recursively
  â”œâ”€â†’ Find all *.md, *.pdf files
  â”œâ”€â†’ For each file:
  â”‚   â”œâ”€â†’ Read content
  â”‚   â”œâ”€â†’ Compute SHA256 hash
  â”‚   â”œâ”€â†’ Check if exists with same hash (skip if yes)
  â”‚   â”œâ”€â†’ Chunk content:
  â”‚   â”‚   â”œâ”€ Markdown: Use MarkdownChunker (AST)
  â”‚   â”‚   â””â”€ PDF: Simple paragraph-based chunking
  â”‚   â”œâ”€â†’ For each chunk:
  â”‚   â”‚   â”œâ”€ Generate embedding (BAAI/bge-m3)
  â”‚   â”‚   â”œâ”€ Insert to chunks table
  â”‚   â”‚   â”œâ”€ (Trigger) Auto-insert to chunks_fts
  â”‚   â”‚   â”œâ”€ (Trigger) Auto-insert to chunks_vec
  â”‚   â”‚   â””â”€ Store metadata (headers, language, etc.)
  â”‚   â””â”€â†’ Update collection stats
  â””â”€â†’ Return progress
```

### Markdown Chunking Algorithm

```
MarkdownChunker::chunk(markdown)
  â”œâ”€â†’ Initialize header_stack = []
  â”œâ”€â†’ Parse using pulldown-cmark
  â”œâ”€â†’ For each event:
  â”‚   â”œâ”€ Start(Heading) â†’ Flush current chunk
  â”‚   â”œâ”€ End(Heading) â†’ Push to header_stack (maintain depth)
  â”‚   â”œâ”€ Start(CodeBlock) â†’ Flush current chunk, mark in_code_block
  â”‚   â”œâ”€ End(CodeBlock) â†’ Create atomic chunk (NEVER SPLIT)
  â”‚   â”œâ”€ Text â†’ Accumulate in current_chunk
  â”‚   â”‚           Flush if > MAX_CHUNK_SIZE (1000 chars)
  â”‚   â””â”€ [Other events] â†’ Handle as needed
  â”œâ”€â†’ Each chunk stores:
  â”‚   â”œâ”€ content (string)
  â”‚   â”œâ”€ headers (Vec<String> with full hierarchy)
  â”‚   â”œâ”€ chunk_type ("code" | "text")
  â”‚   â”œâ”€ language (Option<String> for code)
  â”‚   â””â”€ line numbers (start, end)
  â””â”€â†’ Return Vec<ChunkInfo>
```

---

## 10. Performance Metrics & Targets

### Current Performance (from PHASE1_SUMMARY.md):

**Indexing**:
- Target: > 100 docs/s
- Database: SQLite FTS5 + sqlite-vec optimized

**Search**:
- Target: < 200ms P95 latency
- Vector KNN: 10-100x faster with sqlite-vec indices

**Data Scale**:
- Target: 100k+ chunks
- Per-chunk embedding: 1024 dimensions (4KB per chunk)

### Optimization Checklist:

Database:
- [x] WAL mode for concurrency
- [x] FTS5 with porter tokenizer
- [x] sqlite-vec for KNN
- [ ] Connection pooling
- [ ] Query result caching

Vector Search:
- [ ] Batch embedding (currently single-text)
- [ ] Vector quantization (reduce 1024 to 768)
- [ ] Approximate KNN (LSH)

Application:
- [ ] Result pagination
- [ ] Lazy loading
- [ ] Request deduplication

---

## 11. Known Limitations & Issues

### Current Limitations:

1. **Batch Embedding Not Implemented**
   - Currently embedding chunks one-by-one
   - Should batch for 5-10x speedup

2. **Incremental Indexing Incomplete**
   - File watcher running but not integrated
   - Every change triggers full re-index

3. **No Query Caching**
   - Identical queries re-computed
   - Should cache top-N results

4. **Scanned PDF Detection Heuristic**
   - Simple char/page ratio
   - No actual OCR (requires Tesseract)

5. **No Vector Quantization**
   - Full 1024-dim vectors stored
   - Could reduce to 768 dims with minimal loss

### Build Issues:

- GTK dependencies required for Tauri GUI (atk, gdk-pixbuf, pango)
- Not a code issue, just CI environment setup

---

## 12. Development Guidance

### Running Tests

```bash
cd src-tauri
cargo test --lib                    # All library tests
cargo test --lib db::               # Database tests only
cargo test --lib chunker::          # Chunker tests only
cargo test --lib search::           # Search tests only
cargo test --lib embeddings::       # Embedding tests only
```

### Running Full App

```bash
npm run tauri dev                   # Development mode
npm run tauri build                 # Production build
```

### Key Code Locations

**Search Logic**:
- Primary: `/home/user/deepseeker/src-tauri/src/search.rs:99-260`
- Hybrid scoring: Line 238
- Weight constants: Line 9-10

**Chunking Logic**:
- Core: `/home/user/deepseeker/src-tauri/src/chunker.rs:48-169`
- Header tracking: Line 64-84
- Code block preservation: Line 86-126

**Database Schema**:
- Tables: `/home/user/deepseeker/src-tauri/src/db.rs:37-192`
- Triggers: Line 104-169

**ONNX Integration**:
- Model loading: `/home/user/deepseeker/src-tauri/src/embeddings.rs:35-72`
- Inference: Line 111-168

---

## 13. Future Enhancement Opportunities

1. **Multi-Modal Search**: Image + text chunks
2. **Query Expansion**: Auto-expand queries with synonyms
3. **Ranking Personalization**: ML-based relevance
4. **Plugin System**: User-defined chunking rules
5. **External Integration**: Notion, Readwise APIs
6. **VSCode Extension**: Integrated search in editor
7. **Mobile App**: iOS/Android via React Native
8. **Distributed Indexing**: Scale to 1M+ chunks

---

